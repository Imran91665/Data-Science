{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "tAb77yZ9fzMG"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\orange pc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\orange\n",
      "[nltk_data]     pc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\orange\n",
      "[nltk_data]     pc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\orange\n",
      "[nltk_data]     pc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "pafL7Li0jyXW"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "KGBhZxleR4cu",
    "outputId": "90235179-871b-4df0-e145-0055c2d27de2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74677</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized that the Windows partition of my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74678</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized that my Mac window partition is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74679</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized the windows partition of my Mac ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74680</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized between the windows partition of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74681</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Just like the windows partition of my Mac is l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74682 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment                                              tweet\n",
       "0      Positive  im getting on borderlands and i will murder yo...\n",
       "1      Positive  I am coming to the borders and I will kill you...\n",
       "2      Positive  im getting on borderlands and i will kill you ...\n",
       "3      Positive  im coming on borderlands and i will murder you...\n",
       "4      Positive  im getting on borderlands 2 and i will murder ...\n",
       "...         ...                                                ...\n",
       "74677  Positive  Just realized that the Windows partition of my...\n",
       "74678  Positive  Just realized that my Mac window partition is ...\n",
       "74679  Positive  Just realized the windows partition of my Mac ...\n",
       "74680  Positive  Just realized between the windows partition of...\n",
       "74681  Positive  Just like the windows partition of my Mac is l...\n",
       "\n",
       "[74682 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.read_csv(\"Tweets.csv\")\n",
    "pd.DataFrame(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "E-UPYqkYR4fF"
   },
   "outputs": [],
   "source": [
    "features = tweets[\"tweet\"]\n",
    "labels = tweets[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "vfS-hp5WR4hW"
   },
   "outputs": [],
   "source": [
    "\n",
    "processed_features = []\n",
    "for sentence in range(0, len(features)):\n",
    "    processed_feature = re.sub(\"(@[A-Za-z0-9_]+)\", \"\",\n",
    "                               str(features[sentence]))\n",
    "    processed_feature = re.sub(\n",
    "        'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+#]|[!*\\(\\),]|' \\\n",
    "        '(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', processed_feature)\n",
    " \n",
    "    processed_feature = re.sub(r\"'\", '', processed_feature)\n",
    " \n",
    "    processed_feature = re.sub(r'\\W', ' ', processed_feature)\n",
    " \n",
    "    processed_feature = re.sub(r'\\s+[a-zA-Z1-9]\\s+', ' ', processed_feature)\n",
    " \n",
    "    processed_feature = re.sub(r'^[a-zA-Z1-9]\\s+', '', processed_feature) \n",
    " \n",
    "    processed_feature = re.sub(r'\\s+[a-zA-Z1-9]$', '', processed_feature) \n",
    " \n",
    "    processed_feature = re.sub(r'\\s+', ' ', processed_feature)\n",
    " \n",
    "    processed_feature = processed_feature.strip()\n",
    " \n",
    "    processed_feature = processed_feature.lower()\n",
    "    \n",
    "    processed_features.append(processed_feature)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "83vBufXIST_2"
   },
   "outputs": [],
   "source": [
    "\n",
    "lemmaTokens = []\n",
    "rawTokens = []\n",
    "lemmatizer = WordNetLemmatizer()\n",
    " \n",
    "# Tokenizing\n",
    "for sentence in processed_features:\n",
    "    tempTokens = sentence.split()\n",
    "    rawTokens.append(tempTokens)\n",
    "    lemmatizedTokens = []\n",
    "    \n",
    "    # proceed lemmatization\n",
    "    for singleToken, tag in pos_tag(tempTokens):\n",
    "        # Preparing for morphological analysis\n",
    "        if tag.startswith(\"NN\"):\n",
    "            pos = 'n'\n",
    "        elif tag.startswith('VB'):\n",
    "            pos = 'v'\n",
    "        else:\n",
    "            pos = 'a'\n",
    "            \n",
    "        token = lemmatizer.lemmatize(singleToken, pos)\n",
    "        \n",
    "        if token not in stopwords.words(\"english\"):\n",
    "            if token.isdigit() == False:\n",
    "                lemmatizedTokens.append(token)\n",
    "        \n",
    "    # append the lemmatized tokens of sentence in the list\n",
    "    lemmaTokens.append(lemmatizedTokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "IWxp7FecSUCM"
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "for tok in lemmaTokens:\n",
    "    if len(tok)==0:\n",
    "        lemmaTokens.pop(count)\n",
    "        rawTokens.pop(count)\n",
    "        labels.pop(count)\n",
    "        \n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KPY92Y78SUEU"
   },
   "outputs": [],
   "source": [
    "\n",
    "words = set()\n",
    "for documentTokens in lemmaTokens:\n",
    "    for token in documentTokens:\n",
    "        words.add(token)\n",
    "uniqueWords = list(words)\n",
    "documents = []\n",
    "for i in range(0,len(lemmaTokens)):\n",
    "    documents.append(dict.fromkeys(uniqueWords,0))\n",
    "    \n",
    "count = 0\n",
    "for documentTokens in lemmaTokens:\n",
    "    for token in documentTokens:\n",
    "        documents[count][token]+=1\n",
    "    count+=1\n",
    "\n",
    "def calculateTF(wordDict, bow):\n",
    "    tfDict = {}\n",
    "    bowCount = len(bow)\n",
    "    for word, count in wordDict.items():\n",
    "        if bowCount == 0:\n",
    "            print(wordDict)\n",
    "            print(bow)\n",
    "        try:\n",
    "            tfDict[word] = count/float(bowCount)\n",
    "        except ZeroDivisionError:\n",
    "            print(\"error\")\n",
    "    return tfDict\n",
    " \n",
    "TF = []\n",
    "count = 0\n",
    "for document in documents:\n",
    "    TF.append(calculateTF(document,lemmaTokens[count]))\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DErNQhAFR4lk"
   },
   "outputs": [],
   "source": [
    "def calculateIDF(docList):\n",
    "    import math\n",
    "    idfDict = {}\n",
    "    N = len(docList)\n",
    "    \n",
    "    idfDict = dict.fromkeys(docList[0].keys(), 0)\n",
    "    for doc in docList:\n",
    "        for word, val in doc.items():\n",
    "            if val > 0:\n",
    "                idfDict[word] += 1\n",
    "    \n",
    "    for word, val in idfDict.items():\n",
    "        idfDict[word] = math.log10(N / float(val))\n",
    "        \n",
    "    return idfDict\n",
    "\n",
    "IDFs = calculateIDF(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PEQNYNGMSvTP"
   },
   "outputs": [],
   "source": [
    "\n",
    "def calculateTFIDF(tfBow, idfs):\n",
    "    tfidf = {}\n",
    "    for word, val in tfBow.items():\n",
    "        tfidf[word] = val*idfs[word]\n",
    "    return tfidf\n",
    " \n",
    "TFIDF = []\n",
    "count = 0\n",
    "for document in TF:\n",
    "    TFIDF.append(calculateTFIDF(document,IDFs))\n",
    "    count += 1\n",
    "\n",
    "TFIDF = pd.DataFrame(TFIDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NqPmFmE7SvVb"
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(TFIDF, labels, test_size=0.2, random_state = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bXPhFhVfSvZ9",
    "outputId": "29413fc5-68f5-48e6-f8cc-ab53c9aca4b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=RandomForestClassifier())"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "OvR = OneVsRestClassifier(RandomForestClassifier())\n",
    "OvR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nl-XG-BgW_KJ",
    "outputId": "f031f2df-2bce-4101-9756-ff9e5e8db708"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8872506504770165"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OvR.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ezqfl0NSW_Mb",
    "outputId": "ed6b6a50-37fe-433e-da65-4844dc6992b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest--> Accuracy for all iteration  [89.93928881 90.24284475 89.76582827 89.80919341 89.02862099]\n",
      "Random Forest-->Mean Accuracy 89.76\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf  = RandomForestClassifier()\n",
    "Sfolds = StratifiedKFold(n_splits=5,shuffle=True)\n",
    "sc_Srf=cross_val_score(rf,TFIDF,labels,cv=Sfolds)*100\n",
    "print('Random Forest--> Accuracy for all iteration ', sc_Srf)\n",
    "ME_Srf = sc_Srf.mean()\n",
    "print('Random Forest-->Mean Accuracy %.2f' %ME_Srf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZvjIct_eW_Ol",
    "outputId": "10d9436b-a765-40a8-87a9-82365878cca5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest--> Accuracy for all iteration  [89.08145581 89.94800693 88.04159445 87.694974   90.46793761 87.34835355\n",
      " 87.86828423 89.42807626 85.6152513  89.08145581 86.97916667 92.1875\n",
      " 89.93055556 88.71527778 89.40972222 89.0625     89.0625     89.23611111\n",
      " 91.66666667 91.31944444]\n",
      "Random Forest-->Mean Accuracy 89.11\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf  = RandomForestClassifier(n_estimators=50)\n",
    "Sfolds = StratifiedKFold(n_splits=4,shuffle=True)\n",
    "sc_Srf=cross_val_score(rf,TFIDF,labels,cv=20)*100\n",
    "print('Random Forest--> Accuracy for all iteration ', sc_Srf)\n",
    "ME_Srf = sc_Srf.mean()\n",
    "print('Random Forest-->Mean Accuracy %.2f' %ME_Srf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eM4DrhHqW_Q3"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf  = RandomForestClassifier()\n",
    "Sfolds = StratifiedKFold(n_splits=4,shuffle=True)\n",
    "sc_Srf=cross_val_score(rf,TFIDF,labels,cv=246)*100\n",
    "print('Random Forest--> Accuracy for all iteration ', sc_Srf)\n",
    "ME_Srf = sc_Srf.mean()\n",
    "print('Random Forest-->Mean Accuracy %.2f' %ME_Srf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_tzKhsfoW_TM",
    "outputId": "b0af6151-7a34-4f51-db8b-e380eb894f2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest--> Accuracy for all iteration  [88.90814558 89.77469671 88.04159445 89.60138648 89.60138648 86.48180243\n",
      " 86.65511265 89.60138648 85.96187175 88.3882149  86.97916667 91.49305556\n",
      " 91.14583333 89.23611111 89.0625     87.84722222 88.02083333 89.75694444\n",
      " 91.49305556 90.97222222]\n",
      "Random Forest-->Mean Accuracy 88.95\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf  = RandomForestClassifier(n_estimators=50)\n",
    "Sfolds = StratifiedKFold(n_splits=246,shuffle=True)\n",
    "sc_Srf=cross_val_score(rf,TFIDF,labels,cv=20)*100\n",
    "print('Random Forest--> Accuracy for all iteration ', sc_Srf)\n",
    "ME_Srf = sc_Srf.mean()\n",
    "print('Random Forest-->Mean Accuracy %.2f' %ME_Srf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 227
    },
    "id": "3t8_yny5W_V1",
    "outputId": "fc7214b1-f999-4732-9d12-68773ab93019"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-641b7830c6c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlogic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlogic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mlogic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression  \n",
    "logic=LogisticRegression()\n",
    "logic.fit(X_train,y_train)\n",
    "logic.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uZWVZkvYR4sO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e-cKXbbmR4uY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "SA-ELA 2.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
